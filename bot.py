import os
import json
import logging
from typing import Dict, List

from aiogram import Bot, Dispatcher, F, types
from aiogram.enums import ParseMode
from aiogram.filters import Command
from aiogram.types import Message, ReplyKeyboardMarkup, KeyboardButton, BufferedInputFile
from aiogram.client.default import DefaultBotProperties
from aiogram.utils.keyboard import ReplyKeyboardBuilder
from aiohttp import ClientSession, FormData

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–æ–≤
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è
TOKEN = os.getenv("TELEGRAM_BOT_TOKEN")
OPENROUTER_API_KEY = os.getenv("OPENROUTER_API_KEY")
BASE_URL = os.getenv("BASE_URL")
SITE_NAME = "AI Telegram Bot"

if not all([TOKEN, OPENROUTER_API_KEY]):
    raise ValueError("–ù–µ –∑–∞–¥–∞–Ω—ã –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è")

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –±–æ—Ç–∞
bot = Bot(token=TOKEN, default=DefaultBotProperties(parse_mode=ParseMode.HTML))
dp = Dispatcher()

# –•—Ä–∞–Ω–µ–Ω–∏–µ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
user_context: Dict[int, List[dict]] = {}
http_session: ClientSession = None

# ========== –ö–ª–∞–≤–∏–∞—Ç—É—Ä–∞ ==========
def get_main_kb() -> ReplyKeyboardMarkup:
    builder = ReplyKeyboardBuilder()
    builder.row(
        KeyboardButton(text="üñº –°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ"),
        KeyboardButton(text="üîÑ –°–±—Ä–æ—Å–∏—Ç—å –∫–æ–Ω—Ç–µ–∫—Å—Ç")
    )
    return builder.as_markup(resize_keyboard=True)

# ========== Gemini API ==========
async def ask_gemini(prompt: str, user_id: int) -> str:
    headers = {
        "Authorization": f"Bearer {OPENROUTER_API_KEY}",
        "Content-Type": "application/json",
        "HTTP-Referer": BASE_URL,
        "X-Title": SITE_NAME
    }
    
    if user_id not in user_context:
        user_context[user_id] = []
    
    # –î–æ–±–∞–≤–ª—è–µ–º –Ω–æ–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ –≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç
    user_context[user_id].append({"role": "user", "content": prompt})
    
    payload = {
        "model": "google/gemini-2.0-flash-exp:free",
        "messages": user_context[user_id][-6:],  # –ë–µ—Ä–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–µ 6 —Å–æ–æ–±—â–µ–Ω–∏–π
        "temperature": 0.7
    }
    
    try:
        async with http_session.post(
            "https://openrouter.ai/api/v1/chat/completions",
            headers=headers,
            json=payload
        ) as response:
            data = await response.json()
            
            if response.status == 200:
                reply = data["choices"][0]["message"]["content"]
                # –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ—Ç–≤–µ—Ç –º–æ–¥–µ–ª–∏ –≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç
                user_context[user_id].append({"role": "assistant", "content": reply})
                return reply
            else:
                error_msg = data.get("error", {}).get("message", "Unknown error")
                logger.error(f"Gemini error: {error_msg}")
                return f"‚ùå –û—à–∏–±–∫–∞: {error_msg}"
                
    except Exception as e:
        logger.error(f"Gemini request failed: {str(e)}")
        return "‚ö†Ô∏è –ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –∑–∞–ø—Ä–æ—Å–∞"

# ========== Stable Diffusion API ==========
async def generate_image(prompt: str) -> bytes:
    headers = {
        "Authorization": f"Bearer {OPENROUTER_API_KEY}",
        "Content-Type": "application/json",
        "HTTP-Referer": BASE_URL,
        "X-Title": SITE_NAME
    }
    
    payload = {
        "model": "stabilityai/stable-diffusion-xl-base-1.0",
        "input": {
            "prompt": prompt,
            "negative_prompt": "blurry, low quality, text, watermark",
            "width": 1024,
            "height": 1024,
            "num_inference_steps": 30
        }
    }
    
    try:
        async with http_session.post(
            "https://openrouter.ai/api/v1/images/generations",
            headers=headers,
            json=payload
        ) as response:
            data = await response.json()
            
            if response.status == 200:
                image_url = data["data"][0]["url"]
                # –°–∫–∞—á–∏–≤–∞–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
                async with http_session.get(image_url) as img_response:
                    return await img_response.read()
            else:
                error_msg = data.get("error", {}).get("message", "Unknown error")
                logger.error(f"Image gen error: {error_msg}")
                return None
                
    except Exception as e:
        logger.error(f"Image generation failed: {str(e)}")
        return None

# ========== –û–±—Ä–∞–±–æ—Ç—á–∏–∫–∏ —Å–æ–æ–±—â–µ–Ω–∏–π ==========
@dp.message(Command("start", "help"))
async def cmd_start(message: Message):
    await message.answer(
        "‚ú® <b>AI –ë–æ—Ç —Å —Ñ—É–Ω–∫—Ü–∏—è–º–∏:</b>\n"
        "- –£–º–Ω—ã–π —á–∞—Ç –Ω–∞ –æ—Å–Ω–æ–≤–µ Gemini Flash\n"
        "- –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π —á–µ—Ä–µ–∑ Stable Diffusion\n\n"
        "–ö–æ–º–∞–Ω–¥—ã:\n"
        "/imagine [–æ–ø–∏—Å–∞–Ω–∏–µ] - –±—ã—Å—Ç—Ä–∞—è –≥–µ–Ω–µ—Ä–∞—Ü–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è",
        reply_markup=get_main_kb()
    )

@dp.message(F.text == "üîÑ –°–±—Ä–æ—Å–∏—Ç—å –∫–æ–Ω—Ç–µ–∫—Å—Ç")
async def reset_context(message: Message):
    user_context.pop(message.from_user.id, None)
    await message.answer("–ö–æ–Ω—Ç–µ–∫—Å—Ç –æ—á–∏—â–µ–Ω!", reply_markup=get_main_kb())

@dp.message(F.text == "üñº –°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ")
async def ask_gen_prompt(message: Message):
    await message.answer("–í–≤–µ–¥–∏—Ç–µ –æ–ø–∏—Å–∞–Ω–∏–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è:")

@dp.message(Command("imagine"))
async def quick_generate(message: Message):
    prompt = message.text.split("/imagine", 1)[1].strip()
    if not prompt:
        await message.answer("‚ùå –£–∫–∞–∂–∏—Ç–µ –æ–ø–∏—Å–∞–Ω–∏–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –ø–æ—Å–ª–µ –∫–æ–º–∞–Ω–¥—ã /imagine")
        return
    
    await process_image_generation(message, prompt)

@dp.message(
    F.text,
    F.reply_to_message.func(
        lambda msg: msg and msg.text == "–í–≤–µ–¥–∏—Ç–µ –æ–ø–∏—Å–∞–Ω–∏–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è:"
    )
)
async def handle_image_prompt(message: Message):
    await process_image_generation(message, message.text)

async def process_image_generation(message: Message, prompt: str):
    await message.answer_chat_action("upload_photo")
    
    image_data = await generate_image(prompt)
    if image_data:
        await message.answer_photo(
            BufferedInputFile(image_data, filename="generated_image.png"),
            caption=f"üé® {prompt}"
        )
    else:
        await message.answer("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ")

@dp.message(F.text)
async def handle_text_message(message: Message):
    if message.text in ["üñº –°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ", "üîÑ –°–±—Ä–æ—Å–∏—Ç—å –∫–æ–Ω—Ç–µ–∫—Å—Ç"]:
        return
        
    reply = await ask_gemini(message.text, message.from_user.id)
    await message.answer(reply, reply_markup=get_main_kb())

# ========== –ó–∞–ø—É—Å–∫ –±–æ—Ç–∞ ==========
async def on_startup():
    global http_session
    http_session = ClientSession()
    logger.info("Bot started")

async def on_shutdown():
    await http_session.close()
    await bot.session.close()
    logger.info("Bot stopped")

if __name__ == "__main__":
    from aiogram import executor
    executor.start_polling(
        dp,
        skip_updates=True,
        on_startup=on_startup,
        on_shutdown=on_shutdown
    )