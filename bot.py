import os
import json
import logging
import asyncio
from typing import Dict, Optional

from aiogram import Bot, Dispatcher, F, types
from aiogram.enums import ParseMode
from aiogram.filters import Command
from aiogram.types import Message, ReplyKeyboardMarkup, KeyboardButton, BufferedInputFile
from aiogram.client.default import DefaultBotProperties
from aiogram.utils.keyboard import ReplyKeyboardBuilder
from aiogram.webhook.aiohttp_server import SimpleRequestHandler, setup_application
from aiohttp import web, ClientSession
from dotenv import load_dotenv

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–æ–≤
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# –ó–∞–≥—Ä—É–∑–∫–∞ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
load_dotenv()
TOKEN = os.getenv("TELEGRAM_BOT_TOKEN")
OPENROUTER_API_KEY = os.getenv("OPENROUTER_API_KEY")
BASE_URL = os.getenv("BASE_URL")
PORT = int(os.getenv("PORT"))
SITE_URL = os.getenv("SITE_URL", "https://your-telegram-bot.com")
SITE_NAME = os.getenv("SITE_NAME", "AI Telegram Bot")

# –ü—Ä–æ–≤–µ—Ä–∫–∞ –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã—Ö –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö
if not TOKEN or not OPENROUTER_API_KEY:
    raise ValueError("–ù–µ –∑–∞–¥–∞–Ω—ã –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è")

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –±–æ—Ç–∞
bot = Bot(token=TOKEN, default=DefaultBotProperties(parse_mode=ParseMode.HTML))
dp = Dispatcher()

# –•—Ä–∞–Ω–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö
user_context: Dict[int, Dict] = {}
http_session: Optional[ClientSession] = None

def get_main_kb() -> ReplyKeyboardMarkup:
    builder = ReplyKeyboardBuilder()
    builder.row(
        KeyboardButton(text="üñº –°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ"),
        KeyboardButton(text="üîÑ –°–±—Ä–æ—Å–∏—Ç—å –∫–æ–Ω—Ç–µ–∫—Å—Ç")
    )
    return builder.as_markup(resize_keyboard=True)

async def generate_image(prompt: str) -> Optional[bytes]:
    """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è —á–µ—Ä–µ–∑ Stable Diffusion XL"""
    headers = {
        "Authorization": f"Bearer {OPENROUTER_API_KEY}",
        "Content-Type": "application/json",
        "HTTP-Referer": SITE_URL,
        "X-Title": SITE_NAME
    }
    
    payload = {
        "model": "stabilityai/stable-diffusion-xl-base-1.0",
        "input": {
            "prompt": prompt,
            "negative_prompt": "—Ä–∞–∑–º—ã—Ç–æ, –Ω–∏–∑–∫–æ–µ –∫–∞—á–µ—Å—Ç–≤–æ, –∞—Ä—Ç–µ—Ñ–∞–∫—Ç—ã",
            "width": 1024,
            "height": 1024,
            "num_inference_steps": 30
        }
    }
    
    try:
        async with http_session.post(
            "https://openrouter.ai/api/v1/images/generations",
            headers=headers,
            json=payload
        ) as response:
            if response.status != 200:
                error_text = await response.text()
                logger.error(f"–û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏: {response.status} - {error_text}")
                return None
                
            data = await response.json()
            
            if "data" in data and data["data"]:
                image_url = data["data"][0]["url"]
                async with http_session.get(image_url) as img_response:
                    if img_response.status == 200:
                        return await img_response.read()
                    logger.error(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è: {img_response.status}")
            return None
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è: {str(e)}")
        return None

async def ask_llama(prompt: str, user_id: int) -> str:
    """–ó–∞–ø—Ä–æ—Å –∫ Llama 4 Mavericks —á–µ—Ä–µ–∑ OpenRouter"""
    headers = {
        "Authorization": f"Bearer {OPENROUTER_API_KEY}",
        "Content-Type": "application/json",
        "HTTP-Referer": SITE_URL,
        "X-Title": SITE_NAME
    }
    
    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
    if user_id not in user_context:
        user_context[user_id] = {"chat_history": []}
    
    # –î–æ–±–∞–≤–ª—è–µ–º –Ω–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å –≤ –∏—Å—Ç–æ—Ä–∏—é
    user_context[user_id]["chat_history"].append({"role": "user", "content": prompt})
    
    payload = {
        "model": "meta/llama-4-maverick:free",  # –ò—Å–ø–æ–ª—å–∑—É–µ–º Llama 4 Mavericks
        "messages": user_context[user_id]["chat_history"][-6:],  # –ü–æ—Å–ª–µ–¥–Ω–∏–µ 6 —Å–æ–æ–±—â–µ–Ω–∏–π
        "temperature": 0.7
    }
    
    try:
        async with http_session.post(
            "https://openrouter.ai/api/v1/chat/completions",
            headers=headers,
            json=payload
        ) as response:
            if response.status != 200:
                error_text = await response.text()
                logger.error(f"–û—à–∏–±–∫–∞ API: {response.status} - {error_text}")
                return f"‚ùå –û—à–∏–±–∫–∞ API (–∫–æ–¥ {response.status})"
            
            data = await response.json()
            
            # –û–±—Ä–∞–±–æ—Ç–∫–∞ –æ—Ç–≤–µ—Ç–∞
            if "choices" in data and data["choices"]:
                reply = data["choices"][0]["message"]["content"]
                user_context[user_id]["chat_history"].append({"role": "assistant", "content": reply})
                return reply
            
            logger.error(f"–ù–µ–æ–∂–∏–¥–∞–Ω–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç –æ—Ç–≤–µ—Ç–∞: {data}")
            return "‚ö†Ô∏è –ü–æ–ª—É—á–µ–Ω –Ω–µ–æ–∂–∏–¥–∞–Ω–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç –æ—Ç–≤–µ—Ç–∞"
            
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –∑–∞–ø—Ä–æ—Å–∞: {str(e)}")
        return f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –∑–∞–ø—Ä–æ—Å–∞: {str(e)}"

@dp.message(Command("start", "help"))
async def cmd_start(message: Message):
    await message.answer(
        "‚ú® <b>AI –ë–æ—Ç —Å —Ñ—É–Ω–∫—Ü–∏—è–º–∏:</b>\n"
        "- –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π —á–µ—Ä–µ–∑ Stable Diffusion\n"
        "- –£–º–Ω—ã–π —á–∞—Ç –Ω–∞ –æ—Å–Ω–æ–≤–µ Llama 4 Mavericks\n\n"
        "–ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ –∫–Ω–æ–ø–∫–∏ –Ω–∏–∂–µ:",
        reply_markup=get_main_kb()
    )

@dp.message(F.text == "üîÑ –°–±—Ä–æ—Å–∏—Ç—å –∫–æ–Ω—Ç–µ–∫—Å—Ç")
async def reset_context(message: Message):
    user_context.pop(message.from_user.id, None)
    await message.answer("–ö–æ–Ω—Ç–µ–∫—Å—Ç –æ—á–∏—â–µ–Ω!", reply_markup=get_main_kb())

@dp.message(F.text == "üñº –°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ")
async def ask_gen_prompt(message: Message):
    user_id = message.from_user.id
    if user_id not in user_context:
        user_context[user_id] = {}
    user_context[user_id]["awaiting_image_prompt"] = True
    await message.answer("–í–≤–µ–¥–∏—Ç–µ –æ–ø–∏—Å–∞–Ω–∏–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è:")

@dp.message(F.text)
async def handle_text(message: Message):
    user_id = message.from_user.id
    text = message.text.strip()
    
    if text.lower() == "–æ—Ç–º–µ–Ω–∞":
        user_context.pop(user_id, None)
        await message.answer("–û–ø–µ—Ä–∞—Ü–∏—è –æ—Ç–º–µ–Ω–µ–Ω–∞", reply_markup=get_main_kb())
        return
    
    if user_id in user_context and user_context[user_id].get("awaiting_image_prompt"):
        user_context[user_id].pop("awaiting_image_prompt")
        
        if len(text) > 500:
            await message.answer("‚ùå –°–ª–∏—à–∫–æ–º –¥–ª–∏–Ω–Ω–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ. –ú–∞–∫—Å–∏–º—É–º 500 —Å–∏–º–≤–æ–ª–æ–≤.")
            return
            
        await process_image_generation(message, text)
        return
    
    if text not in ["üñº –°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ", "üîÑ –°–±—Ä–æ—Å–∏—Ç—å –∫–æ–Ω—Ç–µ–∫—Å—Ç"]:
        reply = await ask_llama(text, user_id)
        await message.answer(reply, reply_markup=get_main_kb())

async def process_image_generation(message: Message, prompt: str):
    await bot.send_chat_action(message.chat.id, "upload_photo")
    image_data = await generate_image(prompt)
    
    if image_data:
        await message.answer_photo(
            BufferedInputFile(image_data, "generated_image.png"),
            caption=f"üé® {prompt}"
        )
    else:
        await message.answer("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –¥—Ä—É–≥–æ–π –∑–∞–ø—Ä–æ—Å.")

async def keep_alive():
    """–ü–µ—Ä–∏–æ–¥–∏—á–µ—Å–∫–∏–µ –∑–∞–ø—Ä–æ—Å—ã –¥–ª—è –ø–æ–¥–¥–µ—Ä–∂–∞–Ω–∏—è –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏"""
    while True:
        try:
            async with http_session.get(f"{BASE_URL}/healthz") as resp:
                logger.info(f"Keep-alive: {resp.status}")
        except Exception as e:
            logger.error(f"Keep-alive failed: {str(e)}")
        await asyncio.sleep(300)  # –ö–∞–∂–¥—ã–µ 5 –º–∏–Ω—É—Ç

async def health_check(request):
    return web.Response(text="OK")

async def on_startup(app: web.Application):
    global http_session
    http_session = ClientSession()
    
    await bot.set_webhook(
        url=f"{BASE_URL}/webhook",
        drop_pending_updates=True
    )
    asyncio.create_task(keep_alive())
    logger.info("Bot started with keep-alive")

async def on_shutdown(app: web.Application):
    global http_session
    if http_session:
        await http_session.close()
    await bot.delete_webhook()
    logger.info("Bot stopped")

if __name__ == "__main__":
    app = web.Application()
    app.router.add_get("/healthz", health_check)
    
    webhook_handler = SimpleRequestHandler(
        dispatcher=dp,
        bot=bot,
    )
    webhook_handler.register(app, path="/webhook")
    setup_application(app, dp, bot=bot)
    
    app.on_startup.append(on_startup)
    app.on_shutdown.append(on_shutdown)
    
    try:
        web.run_app(
            app,
            host="0.0.0.0",
            port=PORT,
            access_log=logger
        )
    except Exception as e:
        logger.error(f"Server error: {str(e)}")
        raise